To start experiments use launcher.py. The script creates the appropriate number
of VMs and launches the tensorflow script on each vm 

To monitor progress of the experiment use monitor.py. The script will report
the % completion for running training tasks. The name, number of workers,
ps and training steps should correspond the launcher.py script inputs.

I would recommend running the monitor.py script in different windows of
a screen session because this script will run until the training completes.

After training completes (monitor.py will detect this on its own), a directory
with <name>_data will be created for storing output. We need the following
data in the directory before we can safely delete the VM:
> BW_stats.txt (measures network BW at ps every half hour)
> accuracy_with_steps_worker<id>.py 
> checkpoints (directory with checkpoints collected from main worker)
> worker_<id> (directory for each worker; contains the train_output.log file)


NOTE: In some places, the scripts has some hard constants because they were
designed for 1 ps. If multiple ps are going to be created, replace the constants
with the necessary ps id.


*********************************************************************************

For the approximation runs, these scripts will be useful (a cycle consists of 
launching these scripts in the following order)

launcher_justrun.py - launch the approximation run
monitor_2.py - monitor the progress of a run/ copy all the necessary files after 
	       the run finishes
launcher_killall.py - kill all python processes and erase files

the --help flag should be used to see what files need to be specified

I have added comments with #SANDEEP in the launcher_justrun.py so that you can
modify the script as necessary for the approximation runs

CAUTION: check that all the files have been copied by the monitor_2.py before you
use the launcher_killall.py
